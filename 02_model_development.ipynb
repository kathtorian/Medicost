{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d9607e",
   "metadata": {},
   "source": [
    "# Medicost - Model Development & Optimization Pipeline\n",
    "### Machine Learning Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ce685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/insurance.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA LOADING AND PREPARATION\n",
    "df = pd.read_csv('../data/insurance.csv')\n",
    "    \n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "# Clean and encode the data for machine learning\n",
    "\n",
    "# Create a copy of the original data\n",
    "data = df.copy()\n",
    "\n",
    "print(\"üîÑ Encoding categorical variables...\")\n",
    "\n",
    "# Initialize label encoders dictionary\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['sex', 'smoker', 'region']\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"üîÑ Creating engineered features...\")\n",
    "\n",
    "# Create BMI categories\n",
    "data['bmi_category'] = pd.cut(data['bmi'], \n",
    "                            bins=[0, 18.5, 25, 30, float('inf')], \n",
    "                            labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "# Create age groups\n",
    "data['age_group'] = pd.cut(data['age'], \n",
    "                         bins=[0, 25, 35, 50, 65, float('inf')], \n",
    "                         labels=[0, 1, 2, 3, 4]).astype(int)\n",
    "\n",
    "print(\"‚úÖ Data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831920b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE PREPARATION AND DATA SPLITTING\n",
    "# Prepare features and target variable, then split the data\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['charges'])\n",
    "y = data['charges']\n",
    "\n",
    "# Split the data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data split: {X_train.shape[0]} train samples, {X_test.shape[0]} test samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2772adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE SCALING\n",
    "# Scale numerical features for better model performance\n",
    "\n",
    "# Initialize and fit the scaler on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Feature scaling completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d8beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING\n",
    "# Train multiple models and compare performance\n",
    "\n",
    "print(\"üîÑ Training models...\")\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Store results and trained models\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "# Train each model\n",
    "for name, model in models.items():\n",
    "    print(f\"   Training {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae\n",
    "    }\n",
    "    \n",
    "    trained_models[name] = model\n",
    "\n",
    "print(\"‚úÖ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b42199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL COMPARISON AND SELECTION\n",
    "# Compare all models and select the best performer\n",
    "\n",
    "print(\"üìä Model Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    name: {\n",
    "        'Test R¬≤': metrics['test_r2'],\n",
    "        'Test RMSE': metrics['test_rmse'],\n",
    "        'Test MAE': metrics['test_mae'],\n",
    "        'Overfitting': metrics['train_r2'] - metrics['test_r2']\n",
    "    }\n",
    "    for name, metrics in results.items()\n",
    "}).T\n",
    "\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Select best model (highest Test R¬≤)\n",
    "best_model_name = comparison_df['Test R¬≤'].idxmax()\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Accuracy (R¬≤): {comparison_df.loc[best_model_name, 'Test R¬≤']:.4f} ({comparison_df.loc[best_model_name, 'Test R¬≤']*100:.2f}%)\")\n",
    "print(f\"   RMSE: ${comparison_df.loc[best_model_name, 'Test RMSE']:.2f}\")\n",
    "print(f\"   MAE: ${comparison_df.loc[best_model_name, 'Test MAE']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fa132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION FUNCTION\n",
    "# Create a function to make predictions for new data\n",
    "\n",
    "def predict_insurance_cost(age, sex, bmi, children, smoker, region):\n",
    "    \"\"\"\n",
    "    Predict insurance cost for new customer data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create input DataFrame\n",
    "    input_data = pd.DataFrame({\n",
    "        'age': [age],\n",
    "        'sex': [sex],\n",
    "        'bmi': [bmi],\n",
    "        'children': [children],\n",
    "        'smoker': [smoker],\n",
    "        'region': [region]\n",
    "    })\n",
    "    \n",
    "    # Apply same preprocessing as training data\n",
    "    for col, encoder in label_encoders.items():\n",
    "        input_data[col] = encoder.transform(input_data[col])\n",
    "    \n",
    "    # Add engineered features\n",
    "    input_data['bmi_category'] = pd.cut(input_data['bmi'], \n",
    "                                      bins=[0, 18.5, 25, 30, float('inf')], \n",
    "                                      labels=[0, 1, 2, 3]).astype(int)\n",
    "    \n",
    "    input_data['age_group'] = pd.cut(input_data['age'], \n",
    "                                   bins=[0, 25, 35, 50, 65, float('inf')], \n",
    "                                   labels=[0, 1, 2, 3, 4]).astype(int)\n",
    "    \n",
    "    # Scale features\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = best_model.predict(input_scaled)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "print(\"‚úÖ Prediction function created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# Analyze which features are most important for predictions\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # Get feature importances\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Create DataFrame\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"üìä Feature Importance Ranking:\")\n",
    "    print(\"=\" * 40)\n",
    "    for idx, row in feature_importance_df.iterrows():\n",
    "        print(f\"{row['Feature']:15} | {row['Importance']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Selected model doesn't support feature importance analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXAMPLE PREDICTIONS AND TESTING\n",
    "# Test the prediction function with example cases\n",
    "\n",
    "print(\"üîÆ Example Predictions:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (25, 'female', 22.0, 0, 'no', 'northeast'),\n",
    "    (45, 'male', 30.0, 2, 'yes', 'southeast'),\n",
    "    (35, 'female', 25.0, 1, 'no', 'northwest')\n",
    "]\n",
    "\n",
    "case_names = ['Young Non-Smoker', 'Middle-aged Smoker', 'Average Case']\n",
    "\n",
    "for i, case in enumerate(test_cases):\n",
    "    prediction = predict_insurance_cost(*case)\n",
    "    print(f\"{case_names[i]:18} | ${prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a1339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL VALIDATION AND FINAL RESULTS\n",
    "# Summary of model performance and final validation\n",
    "\n",
    "# Final predictions on test set\n",
    "final_predictions = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate final metrics\n",
    "final_r2 = r2_score(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "final_mae = mean_absolute_error(y_test, final_predictions)\n",
    "\n",
    "print(\"üéØ FINAL MODEL PERFORMANCE:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Accuracy (R¬≤): {final_r2:.4f} ({final_r2*100:.2f}%)\")\n",
    "print(f\"RMSE: ${final_rmse:.2f}\")\n",
    "print(f\"MAE: ${final_mae:.2f}\")\n",
    "\n",
    "# Error analysis\n",
    "errors = final_predictions - y_test\n",
    "print(f\"\\nError Analysis:\")\n",
    "print(f\"Mean Error: ${np.mean(errors):.2f}\")\n",
    "print(f\"Std Error: ${np.std(errors):.2f}\")\n",
    "\n",
    "print(f\"\\nüéâ ML PIPELINE COMPLETED!\")\n",
    "print(f\"Best Model: {best_model_name} with {final_r2*100:.2f}% accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL (Optional)\n",
    "# Save the trained model for future use\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the model and preprocessing objects\n",
    "joblib.dump(best_model, '../models/insurance_model.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "joblib.dump(label_encoders, '../models/encoders.pkl')\n",
    "\n",
    "print(\"üíæ Model saved successfully!\")\n",
    "print(\"Files: insurance_model.pkl, scaler.pkl, encoders.pkl\")\n",
    "\n",
    "# To load later:\n",
    "# model = joblib.load('insurance_model.pkl')\n",
    "# scaler = joblib.load('scaler.pkl') \n",
    "# encoders = joblib.load('encoders.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Medicost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
