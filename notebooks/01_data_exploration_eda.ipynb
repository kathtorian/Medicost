{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abe2763",
   "metadata": {},
   "source": [
    "# Medicost - Data Exploration & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3097da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PART 1: SETUP AND DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING AND INITIAL EXPLORATION\n",
    "# =============================================================================\n",
    "\n",
    "# Load the primary dataset\n",
    "df = pd.read_csv('../data/insurance.csv')\n",
    "\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nüîç DATASET INFO:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nüìã FIRST 5 ROWS:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nüìã LAST 5 ROWS:\")\n",
    "display(df.tail())\n",
    "\n",
    "print(\"\\nüî¢ BASIC STATISTICS:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nüîÑ Duplicate rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA QUALITY ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Missing values analysis\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "if len(missing_data) == 0:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Missing Values Summary:\")\n",
    "    display(missing_data)\n",
    "\n",
    "# Data types analysis\n",
    "print(\"\\nüìä DATA TYPES SUMMARY:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Unique values for categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nüè∑Ô∏è  CATEGORICAL COLUMNS: {list(categorical_cols)}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"\\n{col}: {unique_count} unique values\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "# =============================================================================\n",
    "# TARGET VARIABLE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ TARGET VARIABLE ANALYSIS (CHARGES)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "target_col = 'charges'  # Assuming this is your target variable\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"Target variable: {target_col}\")\n",
    "print(f\"Mean: ${df[target_col].mean():,.2f}\")\n",
    "print(f\"Median: ${df[target_col].median():,.2f}\")\n",
    "print(f\"Std: ${df[target_col].std():,.2f}\")\n",
    "print(f\"Min: ${df[target_col].min():,.2f}\")\n",
    "print(f\"Max: ${df[target_col].max():,.2f}\")\n",
    "print(f\"Skewness: {df[target_col].skew():.2f}\")\n",
    "print(f\"Kurtosis: {df[target_col].kurtosis():.2f}\")\n",
    "\n",
    "# Distribution visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Target Variable (Charges) Distribution Analysis', fontsize=16)\n",
    "\n",
    "# Histogram\n",
    "axes[0,0].hist(df[target_col], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Charges')\n",
    "axes[0,0].set_xlabel('Charges ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "axes[0,1].boxplot(df[target_col])\n",
    "axes[0,1].set_title('Box Plot of Charges')\n",
    "axes[0,1].set_ylabel('Charges ($)')\n",
    "\n",
    "# Log-transformed histogram\n",
    "log_charges = np.log1p(df[target_col])\n",
    "axes[1,0].hist(log_charges, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1,0].set_title('Log-Transformed Charges Distribution')\n",
    "axes[1,0].set_xlabel('Log(Charges + 1)')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "\n",
    "# Q-Q plot for normality\n",
    "from scipy import stats\n",
    "stats.probplot(df[target_col], dist=\"norm\", plot=axes[1,1])\n",
    "axes[1,1].set_title('Q-Q Plot (Normal Distribution)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff31b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA QUALITY ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Missing values analysis\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "if len(missing_data) == 0:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Missing Values Summary:\")\n",
    "    display(missing_data)\n",
    "\n",
    "# Data types analysis\n",
    "print(\"\\nüìä DATA TYPES SUMMARY:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# Unique values for categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nüè∑Ô∏è  CATEGORICAL COLUMNS: {list(categorical_cols)}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"\\n{col}: {unique_count} unique values\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TARGET VARIABLE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ TARGET VARIABLE ANALYSIS (CHARGES)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "target_col = 'charges'  # Assuming this is your target variable\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"Target variable: {target_col}\")\n",
    "print(f\"Mean: ${df[target_col].mean():,.2f}\")\n",
    "print(f\"Median: ${df[target_col].median():,.2f}\")\n",
    "print(f\"Std: ${df[target_col].std():,.2f}\")\n",
    "print(f\"Min: ${df[target_col].min():,.2f}\")\n",
    "print(f\"Max: ${df[target_col].max():,.2f}\")\n",
    "print(f\"Skewness: {df[target_col].skew():.2f}\")\n",
    "print(f\"Kurtosis: {df[target_col].kurtosis():.2f}\")\n",
    "\n",
    "# Distribution visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Target Variable (Charges) Distribution Analysis', fontsize=16)\n",
    "\n",
    "# Histogram\n",
    "axes[0,0].hist(df[target_col], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Charges')\n",
    "axes[0,0].set_xlabel('Charges ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "axes[0,1].boxplot(df[target_col])\n",
    "axes[0,1].set_title('Box Plot of Charges')\n",
    "axes[0,1].set_ylabel('Charges ($)')\n",
    "\n",
    "# Log-transformed histogram\n",
    "log_charges = np.log1p(df[target_col])\n",
    "axes[1,0].hist(log_charges, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1,0].set_title('Log-Transformed Charges Distribution')\n",
    "axes[1,0].set_xlabel('Log(Charges + 1)')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "\n",
    "# Q-Q plot for normality\n",
    "from scipy import stats\n",
    "stats.probplot(df[target_col], dist=\"norm\", plot=axes[1,1])\n",
    "axes[1,1].set_title('Q-Q Plot (Normal Distribution)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a114564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UNIVARIATE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä UNIVARIATE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Numerical columns analysis\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Numerical columns: {list(numerical_cols)}\")\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col != target_col:  # Skip target variable as we analyzed it above\n",
    "        print(f\"\\n--- {col.upper()} ---\")\n",
    "        print(f\"Mean: {df[col].mean():.2f}\")\n",
    "        print(f\"Median: {df[col].median():.2f}\")\n",
    "        print(f\"Std: {df[col].std():.2f}\")\n",
    "        print(f\"Range: {df[col].min()} - {df[col].max()}\")\n",
    "        print(f\"Unique values: {df[col].nunique()}\")\n",
    "\n",
    "# Visualization for numerical variables\n",
    "if len(numerical_cols) > 1:\n",
    "    fig, axes = plt.subplots(2, len(numerical_cols)//2 + len(numerical_cols)%2, figsize=(15, 8))\n",
    "    axes = axes.ravel() if len(numerical_cols) > 2 else [axes] if len(numerical_cols) == 2 else axes\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        if col != target_col and i < len(axes):\n",
    "            axes[i].hist(df[col], bins=30, alpha=0.7, edgecolor='black')\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "            axes[i].set_xlabel(col)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018bed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BIVARIATE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîó BIVARIATE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv('../data/processed/insurance_processed.csv')\n",
    "\n",
    "# Correlation matrix for numerical variables\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "print(\"Correlation with target variable (charges):\")\n",
    "target_correlations = correlation_matrix[target_col].abs().sort_values(ascending=False)\n",
    "print(target_correlations)\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "           square=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Categorical vs Target analysis\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n--- {col.upper()} vs CHARGES ---\")\n",
    "    \n",
    "    # Group statistics\n",
    "    group_stats = df.groupby(col)[target_col].agg(['mean', 'median', 'std', 'count'])\n",
    "    print(group_stats)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(data=df, x=col, y=target_col)\n",
    "    plt.title(f'{col} vs Charges (Box Plot)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.violinplot(data=df, x=col, y=target_col)\n",
    "    plt.title(f'{col} vs Charges (Violin Plot)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edf21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced correlation heatmap for presentation - ALL features\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress Streamlit warnings\n",
    "\n",
    "# Create a copy of the dataframe for encoding\n",
    "df_corr = df.copy()\n",
    "\n",
    "# Encode ALL categorical variables properly\n",
    "df_corr['sex'] = (df_corr['sex'] == 'male').astype(int)\n",
    "df_corr['smoker'] = (df_corr['smoker'] == 'yes').astype(int)\n",
    "\n",
    "# Handle region encoding\n",
    "region_encoded = pd.get_dummies(df_corr['region'], prefix='region')\n",
    "df_corr = pd.concat([df_corr.drop('region', axis=1), region_encoded], axis=1)\n",
    "\n",
    "# Drop any remaining non-numeric columns (like age_group if it exists)\n",
    "categorical_cols = df_corr.select_dtypes(include=['object', 'category']).columns\n",
    "df_corr = df_corr.drop(categorical_cols, axis=1)\n",
    "\n",
    "# Remove charges from correlation matrix (but keep for correlation calculation)\n",
    "features_for_corr = df_corr.drop('charges', axis=1)\n",
    "correlation_matrix = features_for_corr.corrwith(df_corr['charges']).to_frame('charges')\n",
    "\n",
    "# Add feature-to-feature correlations\n",
    "feature_corr_matrix = features_for_corr.corr()\n",
    "full_correlation_matrix = pd.concat([feature_corr_matrix, correlation_matrix], axis=1)\n",
    "\n",
    "# Create enhanced heatmap for presentation\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(full_correlation_matrix, \n",
    "            annot=True, \n",
    "            cmap='RdYlBu_r', \n",
    "            center=0,\n",
    "            fmt='.2f',\n",
    "            cbar_kws={\"shrink\": .8},\n",
    "            linewidths=0.5)\n",
    "\n",
    "plt.title('Feature Correlation Matrix with Target\\n(All Features Encoded)', \n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print strongest correlations with target\n",
    "print(\"üéØ STRONGEST CORRELATIONS WITH CHARGES:\")\n",
    "target_correlations = correlation_matrix['charges'].abs().sort_values(ascending=False)\n",
    "for feature, corr in target_correlations.items():\n",
    "    print(f\"{feature:15} | {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical variables\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "           square=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create a copy for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "# 1. Age groups\n",
    "df_fe['age_group'] = pd.cut(df_fe['age'], \n",
    "                           bins=[0, 25, 35, 50, 65, 100], \n",
    "                           labels=['Young Adult (18-25)', 'Adult (26-35)', \n",
    "                                  'Middle Age (36-50)', 'Senior (51-65)', 'Elderly (65+)'])\n",
    "\n",
    "# 2. BMI categories\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif bmi < 25:\n",
    "        return 'Normal'\n",
    "    elif bmi < 30:\n",
    "        return 'Overweight'\n",
    "    else:\n",
    "        return 'Obese'\n",
    "\n",
    "df_fe['bmi_category'] = df_fe['bmi'].apply(categorize_bmi)\n",
    "\n",
    "# 3. High-risk indicators\n",
    "df_fe['is_smoker'] = (df_fe['smoker'] == 'yes').astype(int)\n",
    "df_fe['has_children'] = (df_fe['children'] > 0).astype(int)\n",
    "df_fe['is_obese'] = (df_fe['bmi'] >= 30).astype(int)\n",
    "\n",
    "# 4. Interaction features\n",
    "df_fe['age_bmi_interaction'] = df_fe['age'] * df_fe['bmi']\n",
    "df_fe['smoker_age'] = df_fe['is_smoker'] * df_fe['age']\n",
    "df_fe['smoker_bmi'] = df_fe['is_smoker'] * df_fe['bmi']\n",
    "\n",
    "# 5. Risk score (combined risk factors)\n",
    "df_fe['risk_score'] = (df_fe['is_smoker'] * 3 + \n",
    "                      df_fe['is_obese'] * 2 + \n",
    "                      (df_fe['age'] > 50).astype(int) * 1)\n",
    "\n",
    "print(\"‚úÖ New features created:\")\n",
    "new_features = ['age_group', 'bmi_category', 'is_smoker', 'has_children', \n",
    "               'is_obese', 'age_bmi_interaction', 'smoker_age', 'smoker_bmi', 'risk_score']\n",
    "for feature in new_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "print(f\"\\nDataset shape after feature engineering: {df_fe.shape}\")\n",
    "\n",
    "# Analyze new features\n",
    "print(\"\\nüîç NEW FEATURES ANALYSIS:\")\n",
    "\n",
    "# Age groups vs charges\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(data=df_fe, x='age_group', y='charges')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Age Groups vs Charges')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(data=df_fe, x='bmi_category', y='charges')\n",
    "plt.title('BMI Categories vs Charges')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(data=df_fe, x='risk_score', y='charges')\n",
    "plt.title('Risk Score vs Charges')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ebf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OUTLIER DETECTION AND HANDLING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç OUTLIER DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# IQR method for numerical columns\n",
    "def detect_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "outlier_summary = {}\n",
    "for col in ['age', 'bmi', 'children', 'charges']:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df_fe, col)\n",
    "    outlier_summary[col] = {\n",
    "        'count': len(outliers),\n",
    "        'percentage': (len(outliers) / len(df_fe)) * 100,\n",
    "        'lower_bound': lower,\n",
    "        'upper_bound': upper\n",
    "    }\n",
    "    print(f\"\\n{col.upper()} outliers:\")\n",
    "    print(f\"  Count: {len(outliers)} ({(len(outliers) / len(df_fe)) * 100:.2f}%)\")\n",
    "    print(f\"  Bounds: [{lower:.2f}, {upper:.2f}]\")\n",
    "\n",
    "# Visualization of outliers\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(['age', 'bmi', 'children', 'charges']):\n",
    "    axes[i].boxplot(df_fe[col])\n",
    "    axes[i].set_title(f'{col} - Outlier Detection')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c672cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PREPROCESSING PIPELINE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è DATA PREPROCESSING PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create final processed dataset\n",
    "df_processed = df_fe.copy()\n",
    "\n",
    "# Handle outliers (if needed) - for this dataset, medical outliers might be valid\n",
    "# We'll keep them but create a flag\n",
    "df_processed['has_outlier_charges'] = 0\n",
    "outliers_charges, _, upper_bound_charges = detect_outliers_iqr(df_processed, 'charges')\n",
    "df_processed.loc[outliers_charges.index, 'has_outlier_charges'] = 1\n",
    "\n",
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Label encoding for binary categories\n",
    "le_sex = LabelEncoder()\n",
    "df_processed['sex_encoded'] = le_sex.fit_transform(df_processed['sex'])\n",
    "\n",
    "le_smoker = LabelEncoder()\n",
    "df_processed['smoker_encoded'] = le_smoker.fit_transform(df_processed['smoker'])\n",
    "\n",
    "# One-hot encoding for multi-class categories\n",
    "region_dummies = pd.get_dummies(df_processed['region'], prefix='region')\n",
    "df_processed = pd.concat([df_processed, region_dummies], axis=1)\n",
    "\n",
    "age_group_dummies = pd.get_dummies(df_processed['age_group'], prefix='age_group')\n",
    "df_processed = pd.concat([df_processed, age_group_dummies], axis=1)\n",
    "\n",
    "bmi_category_dummies = pd.get_dummies(df_processed['bmi_category'], prefix='bmi')\n",
    "df_processed = pd.concat([df_processed, bmi_category_dummies], axis=1)\n",
    "\n",
    "print(f\"‚úÖ Categorical variables encoded\")\n",
    "print(f\"Final dataset shape: {df_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db62c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FEATURE CORRELATION WITH TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate correlation with target variable\n",
    "numerical_features = df_processed.select_dtypes(include=[np.number]).columns\n",
    "feature_correlations = df_processed[numerical_features].corr()['charges'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top features correlated with charges:\")\n",
    "top_features = feature_correlations.head(15)\n",
    "print(top_features)\n",
    "\n",
    "# Visualize feature correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features_plot = feature_correlations.head(20)\n",
    "plt.barh(range(len(top_features_plot)), top_features_plot.values)\n",
    "plt.yticks(range(len(top_features_plot)), top_features_plot.index)\n",
    "plt.xlabel('Absolute Correlation with Charges')\n",
    "plt.title('Top 20 Features by Correlation with Target')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df158af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA VALIDATION AND EXPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ DATA VALIDATION AND EXPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Final validation\n",
    "print(\"Final dataset validation:\")\n",
    "print(f\"Shape: {df_processed.shape}\")\n",
    "print(f\"Missing values: {df_processed.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df_processed.duplicated().sum()}\")\n",
    "print(f\"Memory usage: {df_processed.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Data types summary\n",
    "print(\"\\nData types summary:\")\n",
    "print(df_processed.dtypes.value_counts())\n",
    "\n",
    "# Save processed dataset\n",
    "df_processed.to_csv('../data/processed/insurance_processed.csv', index=False)\n",
    "print(\"\\n‚úÖ Processed dataset saved to: ../data/processed/insurance_processed.csv\")\n",
    "\n",
    "# Save feature engineering metadata\n",
    "feature_info = {\n",
    "    'original_features': list(df.columns),\n",
    "    'engineered_features': new_features,\n",
    "    'encoded_features': ['sex_encoded', 'smoker_encoded'] + list(region_dummies.columns) + \n",
    "                       list(age_group_dummies.columns) + list(bmi_category_dummies.columns),\n",
    "    'target_variable': 'charges',\n",
    "    'dataset_shape': df_processed.shape,\n",
    "    'top_features': list(top_features.index[:10])\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/processed/feature_info.json', 'w') as f:\n",
    "    json.dump(feature_info, f, indent=2, default=str)\n",
    "print(\"‚úÖ Feature information saved to: ../data/processed/feature_info.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6418db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY REPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä DATA EXPLORATION & EDA COMPLETION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ COMPLETED TASKS:\n",
    "- ‚úì Project structure created\n",
    "- ‚úì Dataset loaded and explored ({df.shape[0]} rows, {df.shape[1]} columns)\n",
    "- ‚úì Data quality assessment completed\n",
    "- ‚úì Missing values: {df.isnull().sum().sum()} (handled)\n",
    "- ‚úì Target variable analyzed (charges: mean=${df['charges'].mean():,.2f})\n",
    "- ‚úì {len(new_features)} new features engineered\n",
    "- ‚úì Categorical variables encoded\n",
    "- ‚úì Outliers detected and flagged\n",
    "- ‚úì Processed dataset exported\n",
    "\n",
    "üìà KEY INSIGHTS:\n",
    "- Average insurance charge: ${df['charges'].mean():,.2f}\n",
    "- Smoking is highly correlated with charges (r={df_processed[['is_smoker', 'charges']].corr().iloc[0,1]:.3f})\n",
    "- Age and BMI show moderate correlation with charges\n",
    "- {len(outliers_charges)} high-cost outlier cases identified ({(len(outliers_charges)/len(df))*100:.1f}%)\n",
    "\n",
    "üéØ READY FOR MACHINE LEARNING ENGINEERING:\n",
    "- Clean dataset ready for modeling\n",
    "- Feature engineering pipeline established\n",
    "- Target variable understood\n",
    "- Key predictive features identified\n",
    "\n",
    "üìÅ FILES CREATED:\n",
    "- ../data/processed/insurance_processed.csv\n",
    "- ../data/processed/feature_info.json\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Medicost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
